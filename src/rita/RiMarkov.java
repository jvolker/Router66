package rita;

import java.io.PrintStream;
import java.util.*;
import java.util.regex.Pattern;

import processing.core.PApplet;
import rita.support.MarkovModel;
import rita.support.RiTextNode;
import rita.support.ifs.RiMarkovIF;
import rita.support.ifs.RiTokenizerIF;
import rita.support.remote.RemoteMarkov;

/**
 * Performs analysis and text generation via Markov chains (aka N-Grams) 
 * with options to process single characters, words, sentences, and 
 * arbitrary regular expressions. Provides a variety of methods specifically 
 * designed for text-generation. Example usage:<pre>
 *   RiMarkov rm = new RiMarkov(this, 3);
 *   rm.loadFile("war_peace.txt"); // in data dir.
 *   String[] sents = rm.generateSentences(10);
 *   for (int i = 0; i < sents.length; i++) {
 *     System.out.println(sents[i]);
 *   }</pre>
 * 
 * For large models, it is recommended to use this object in server-mode. See RiTaServer
 *  (@link http://www.rednoise.org/rita/documentation/ritaserver_class_ritaserver.htm).  
 * <p>
 * Note: use RiMarkov.setTokenizerRegex() to control how inputs are tokenized (or split-up). 
 * The default is to use the Penn word-tokenizing conventions (without splitting contractions). 
 * You may wish to simply use whitespace (or some other regular expression), which 
 * can be accomplished as follows:<pre>
 *   RiMarkov rm = new RiMarkov(this, 3);
 *   rm.setTokenizerRegex("\\s");</pre>
 *   
 * This creates a new model, with n=3, that tokenizes its
 * input on the whitespace characters: [ \t\n\x0B\f\r].
 * <p> <br>
 * Note: use RiMarkov.setAllowingDuplicates(boolean) method to
 * ensure that sentences that exist in the input test are not output by
 * generate().  This method should be used with care, as certain sets of
 * input texts (with allowDuplicates=false) may result in decreased performance
 * and/or excessive memory use.
 */
public class RiMarkov extends RiObject implements RiMarkovIF
{
  protected RiMarkovIF delegate;
  
  /**
   * Construct a sentence-generating Markov chain (or n-gram) model and set its n-factor 
   * @invisible
   */
  public RiMarkov(int nFactor) {
    this(null, nFactor);  
  }
  
  /**
   * Construct a sentence-generating Markov chain (or n-gram) model and set its n-factor 
   */
  public RiMarkov(PApplet parent, int nFactor) {
    this(parent, nFactor, MarkovModel.DEFAULT_IGNORE_CASE);    
  }
  
  /** 
   * invisible
   */
  public RiMarkov(int nFactor, boolean ignoreCase) {
    this(null, nFactor, ignoreCase);    
  }
  
  public RiMarkov(PApplet pApplet, int nFactor, boolean ignoreCase) 
  {
    super(pApplet);         
    if (!RiTa.isServerEnabled())
      delegate = new MarkovModel(pApplet, nFactor, ignoreCase);
    else
      delegate = new RemoteMarkov(nFactor, ignoreCase);
  }
  
  // Methods ==================================================
 
  public void loadTokens(char[] tokens) {
    delegate.loadTokens(tokens);
  }
  
  public boolean isPrintingIgnoredText() {
    return delegate.isPrintingIgnoredText();
  }

  public void setPrintIgnoredText(boolean printIgnoredText) {
    delegate.setPrintIgnoredText(printIgnoredText);
  }
  
  /**
   * Tells the model to ignore (english-like) sentences in its input 
   * and treat all text tokens the same.
   */
  public void disableSentenceProcessing()
  {
    this.delegate.disableSentenceProcessing();
  }
  
  /**
   * @invisible
   * @deprecated see generateSentence()
   */
  public String generate()
  {
    return this.delegate.generate();
  }
  
  /**
   * Generates a sentence from the model.<p>
   * Note: multiple sentences generated by this method WILL NOT follow 
   * the model across sentence boundaries; thus the following two calls 
   * are NOT equivalent:
   * <pre>
     String[] results = markov.generateSentences(10);
               and
     for (int i = 0; i < 10; i++) {
       results[i] = markov.generateSentence();
     }</pre>
   * The latter will create 10 sentences with no explicit relationship 
   * between one and the next; while the former will follow probabilities 
   * from one sentence (across a boundary) to the next.            
   */
  public String generateSentence()
  {
    return this.delegate.generateSentence();
  }
  
  /**
   * Generates some # (one or more) of sentences from the model.<P>
   * Note: multiple sentences generated by this method WILL follow 
   * the model across sentence boundaries; thus the following two calls 
   * are NOT equivalent:
   * <pre>
     String[] results = markov.generateSentences(10);
               and
     for (int i = 0; i < 10; i++)  {
       results[i] = markov.generateSentence();
     }</pre>
   * The latter will create 10 sentences with no explicit relationship 
   * between one and the next; while the former will follow probabilities 
   * from one sentence (across a boundary) to the next.         
   */
  public String[] generateSentences(int numSentences)
  {
    return this.delegate.generateSentences(numSentences);
  }
  
  /**
   * Generates a string of <code>length</code> tokens from the model.
   */
  public String generateTokens(int length)
  {
    return this.delegate.generateTokens(length);
  }
  
  /**
   * Determines whether to add spaces between generated tokens
   */
  public void setAddSpaces(boolean addSpaces)
  {
    delegate.setAddSpaces(addSpaces);
  }

  /**
   * Returns an unordered list of possible words <i>w</i> that complete
   * an n-gram consisting of: pre[0]...pre[k], <i>w</i>, post[k+1]...post[n].
   * As an example, the following call:
   * <pre>
   * getCompletions(new String[]{ "the" }, new String[]{ "ball" })</pre>
   * will return all the single words that occur between 'the' and 'ball'
   * in the current model (assuming n > 2), e.g., ['red', 'big', 'bouncy']).
   * <p> 
   * Note: For this operation to be valid, (pre.length + post.length)
   * must be strictly less than the model's nFactor, otherwise an 
   * exception will be thrown. 
   */
  public String[] getCompletions(String[] pre, String[] post)
  {
    return this.delegate.getCompletions(pre, post);
  }
  
  /** 
   * Returns all possible next words (or tokens), ordered by probability, for the given
   * seed array, or null if none are found. <p>Note: seed arrays of any size may 
   * be input, but only the last n-1 elements will be considered.   
   */
  public String[] getCompletions(String[] seed)
  {
    return this.delegate.getCompletions(seed);
  }
  /**
   * Returns the current n-value for the model
   */
  public int getNFactor()
  {
    return this.delegate.getNFactor();
  }
  
  /**
   * Determines whether calls to generateSentence(s) will return 
   * sentences that exist (character-for-character) in the input text(s).<p>
   * Note: The trade-off here is between ensuring novel outputs
   * and a potential slow-down due to rejected outputs (b/c they
   * exist in the input text.) Use with care as setting this to true for 
   * large models may result in excessive memory use.      
   */
  public void setAllowDuplicates(boolean allowDuplicateSentences)
  {
    this.delegate.setAllowDuplicates(allowDuplicateSentences);
  }
  
  /** @invisible */
  public boolean isAllowingDuplicates()
  {
    return this.delegate.isAllowingDuplicates();
  }
  /** 
   * Returns the full set of possible next tokens (as a HashMap: 
   * String -> Float (probability)) given an array of tokens 
   * representing the path down the tree (with length less than n).  
   * If the input array length is not less than n, or the path cannot be 
   * found, or the endnode has no children, null is returned.<p>
   * 
   * Note: As the returned Map represents the full set of possible next 
   * tokens, the sum of its probabilities will always be equal 1.
   *   
   * @see #getProbability(String) 
   */
  public Map getProbabilities(String[] path)
  {
    return this.delegate.getProbabilities(path);
  }

  /** 
   * Returns the probability of obtaining
   * a sequence of k character tokens were k <= nFactor,
   * e.g., if nFactor = 3, then valid lengths
   * for the String <code>tokens</code> are 1, 2 & 3.
   */
  public float getProbability(String[] tokens)
  {
    return this.delegate.getProbability(tokens);
  }
  /**
   * Returns the raw (unigram) probability for 
   * a token in the model, or 0 if it does not exist
   */
  public float getProbability(String token)
  {
    return this.delegate.getProbability(token);
  }
  
  /** @invisible */
  public RiTokenizerIF getTokenizer()
  {
    if (delegate instanceof MarkovModel) {
      MarkovModel mm = (MarkovModel) delegate;
      return mm.getTokenizer();
    }
    throw new RiTaException("RiMarkov.getWordTokenizer()"
      + " not available with RiTaServer");
  }
  /**
   * Returns the # of words loaded into the model
   */
  public int getWordCount()
  {
    return this.delegate.getWordCount();
  }
  /** @invisible */
  public boolean isIgnoringCase()
  {
    return this.delegate.isIgnoringCase();
  }
  /** @invisible */
  public boolean isRecognizingSentences()
  {
    return this.delegate.isRecognizingSentences();
  }
  /**
   * Returns whether (add-1) smoothing is enabled for the model
   */
  public boolean isSmoothing()
  {
    return this.delegate.isSmoothing();
  }
  
  /**  
   * Load a text file into the model -- if using Processing,
   * the file should be in the sketch's data folder. 
   * 
   * @param fileName name of file to load
   * 
   * @param multiplier weighting for tokens in the file;<br>  
   * a weight of 3 is equivalent to loading that file 3 times and gives
   * each token 3x the probability of being chosen during generation.
   */
  public void loadFile(String fileName, int multiplier)
  {    
    this.delegate.loadFile(fileName, multiplier);
  }
  
  public void loadFile(String fileName)
  {    
    this.loadFile(fileName,1);
  }
       
  /**
   * Loads an array of sentences into the model; each 
   * element in the array must be a single sentence for
   * proper parsing.
   * 
   * @param multiplier Weighting for sentences in the array<br>  
   * 
   * A weight of 3 is equivalent to loading the sentences 3 times and gives
   * each word within 3x the probability of being chosen during generation.
   */
  public void loadSentences(String[] sentences, int multiplier) {
    this.delegate.loadSentences(sentences, multiplier);
  }
  
  public void loadSentences(String[] sentences)
  {
    this.delegate.loadSentences(sentences);
  }

  /** 
   * Load a String into the model, splitting the text first into sentences,
   * then into words, according to the current regular expression. 
   * 
   * @param multiplier Weighting for tokens in the String <br>  
   * 
   * A weight of 3 is equivalent to loading this text 3 times and gives
   * each token 3x the probability of being chosen during generation.
   */
  public void loadText(String rawText, int multiplier)
  {
    this.delegate.loadText(rawText, multiplier);
  }
  
  public void loadText(String rawText)
  {
    this.delegate.loadText(rawText);
  }
  
  /**
   * Loads an array of tokens (or words) into the model; each 
   * element in the array must be a single token for proper 
   * construction of the model.
   
   * @param multiplier Weighting for tokens in the array<br>  
   * 
   * A weight of 3 is equivalent to loading the tokens 3 times and gives
   * each one 3x the probability of being chosen during generation.
   */
  public void loadTokens(String[] tokens, int multiplier) {
    this.delegate.loadTokens(tokens, multiplier);
  }

  public void loadTokens(String[] tokens)
  {
    this.delegate.loadTokens(tokens);
  }

  /**
   * Outputs a String representing the models probability tree using
   * the supplied print stream (or System.out).<p>
   * 
   * NOTE: this method will block for potentially long periods of time
   * on large models. 
   * 
   * @param printStream where to send the output (default=System.out)
   * @param sort whether the tree is first sorted (by frequency) 
   * before being output
   */
  public void printTree(PrintStream printStream, boolean sort)
  {
    if (delegate instanceof MarkovModel) {
      MarkovModel mm = (MarkovModel) delegate;
      mm.printTree(printStream, sort);
    }
    else throw new RiTaException("RiMarkov.printTree()"
      + " not available when using RiTaServer");
  }
  
  public void printTree()
  {
    this.printTree(System.out, false);
  }
  
  public void printTree(boolean sort)
  {
    this.printTree(System.out, sort);
  }

  public void printTree(PrintStream pw)
  {
    this.printTree(pw, false);
  }
  

  /**
   * Sets whether the model will try to recognize 
   * (english-like) sentences in its input (default=true).
   */
  public void setRecognizeSentences(boolean ignoreSentences)
  {
    this.delegate.setRecognizeSentences(ignoreSentences);
  }
  
  /**
   * @invisible
   * @see RiMarkov#setTokenizerRegex(String)
   */
  public void setTokenizer(RiTokenizer tokenizer)
  {
    if (delegate instanceof MarkovModel) 
      ((MarkovModel) delegate).setTokenizer(tokenizer);    
    throw new RiTaException("RiMarkov.setTokenizer(WordTokenizer) not available "
      + " with the RiTaServer, perhaps try RiMarkov.setTokenizerRegex()?");
  }
  
    
  public RiTextNode getRoot() {
     if (delegate instanceof MarkovModel) 
      return ((MarkovModel) delegate).getRoot();    
    throw new RiTaException("RiMarkov.getRoot() not implemented" 
    		+ " for use with the RiTaServer");
  }

  
  /**
   * Creates a new RegexTokenizer from the supplied regular expression
   * and uses it when adding subsequent data to the model.
   */
  public void setTokenizerRegex(String regex)
  {
    this.delegate.setTokenizerRegex(regex);
  }
  
  /** 
   * Toggles whether (add-1) smoothing is enabled for the model.
   * Should be called before any data loading is done. 
   */
  public void setUseSmoothing(boolean useSmoothing)
  {
    this.delegate.setUseSmoothing(useSmoothing);
  }
  
    /** Sets the minimum # of words allowed in a generated sentence (default=6) */
  public void setMinSentenceLength(int minSentenceLength) {
    delegate.setMinSentenceLength(minSentenceLength);
  }

  /** Returns the minimum # of words allowed in a generated sentence */
  public int getMinSentenceLength() {
    return delegate.getMinSentenceLength();
  }
  
  /** Sets the maximum # of words allowed in a generated sentence (default=35) */
  public void setMaxSentenceLength(int maxSentenceLength) {
    delegate.setMaxSentenceLength(maxSentenceLength);
  }

  /** Returns the maximum # of words allowed in a generated sentence */
  public int getMaxSentenceLength() {
    return delegate.getMaxSentenceLength();
  }

  /** Returns whether the model is ignoring quotations found in the input */
  public boolean isRemovingQuotations() {
    return delegate.isRemovingQuotations();
  }

  /** Tells the model whether to ignore various quotations types in the input (default=true)   */
  public void setRemoveQuotations(boolean removeQuotations) {
    this.delegate.setRemoveQuotations(removeQuotations);
  }
  
  public static void main(String[] args) throws InterruptedException
  {         
    //RiMarkov rm = new RiMarkov(null,3);
/*    RiMarkov mm = new RiMarkov(null, 4);
    mm.setAddSpaces(false);
    String data = RiTa.loadString(null, "tate.txt");
    char[] tokens = data.toCharArray();
    String[] s = new String[tokens.length];
    for (int i = 0; i < s.length; i++)
      s[i] = tokens[i]+"";
    mm.loadTokens(s);
    for (int i = 0; i < 10; i++)
    {
      String word = mm.generateTokens(10);
      System.out.println(i+") "+word);
    }*/
    
/*    String data = RiTa.loadString(null, "kafka.txt");
    String[] tokens = RiTa.split(data, Pattern.compile("(\\b|\\B)"), true);
    for (int i = 0; i < tokens.length; i++)
    {
      System.out.println(i+") "+tokens[i]);
    }*/
    //char[] tokens = data.toCharArray();
    if (1==1) return;
    
/*    RiMarkov mm = new RiMarkov(null, 4);
    mm.loadTokens(tokens);
    mm.generateTokens(mm);
    */
    /*if (1==1) return;
    mm.setAddSpaces(false);
    
    String data = RiTa.loadString(null, "tate.txt");
    char[] tokens = data.toCharArray();
    String[] s = new String[tokens.length];
    for (int i = 0; i < s.length; i++)
      s[i] = tokens[i]+"";
    mm.loadTokens(s);
    for (int i = 0; i < 10; i++)
    {
      String word = mm.generateTokens(10);
      System.out.println(i+") "+word);
    }
*/
    //mm.printTree();
/*    String input = "The dog ran faster than the boy.";
    char[] tokens = input.toCharArray();
    String[] s = new String[tokens.length];
    for (int i = 0; i < tokens.length; i++) 
      s[i] = Character.toString(tokens[i]);    
    rm.loadText(input);   
    rm.printTree();
    RiTextNode root = rm.getRoot();
    System.out.println(root);
    Collection c = root.getChildNodes();
    for (Iterator it = c.iterator(); it.hasNext();) {
      RiTextNode tn = (RiTextNode) it.next();
      System.out.println(tn+": "+tn.getCount());
    }
    
    if (1==1) return;*/
    
/*    rm.disableSentenceProcessing();
    rm.setTokenizerRegex(".");
    rm.loadText("Last Wednesday we decided to visit the zoo. We arrived the next morning after we breakfasted, cashed in our passes and entered. We walked toward the first exhibits. I looked up at a giraffe as it stared back at me. I stepped nervously to the next area. One of the lions gazed at me as he lazed in the shade while the others napped. One of my friends first knocked then banged on the tempered glass in front of the monkeyï¿½s cage. They howled and screamed at us as we hurried to another exhibit where we stopped and gawked at plumed birds. After we rested, we headed for the petting zoo where we petted wooly sheep who only glanced at us but the goats butted each other and nipped our clothes when we ventured too near their closed pen. Later, our tired group nudged their way through the crowded paths and exited the turnstiled gate. Our car bumped, jerked and swayed as we dozed during the relaxed ride home.");
    //rm.setAllowDuplicates(true);
    rm.printTree();
    if (1==1) return;
    //RiTaServer.start((PApplet)null);
    //if (1==1) return;
    //RiTa.useServer(true);
    //RiMarkov rm = new RiMarkov(null,4);
    //rm.setAllowDuplicates(true);
    //rm.loadFile("kafka.txt");
    //rm.printTree();

    System.out.println("1] p(On) = "+rm.getProbability("On"));
    System.out.println("2] p(this|On) = "+rm.getProbability(new String[]{ "On", "this" }));
    
       
    System.out.println("3] map(the|before) = "+rm.getProbabilities(new String[]{  "before", "the" }));
    
    if (1==1) return;
    
    System.out.println("4] next(the|before) = "+RiTa.asList(rm.getCompletions(new String[]{ "before", "the" })));   
    System.out.println("8] getCompletions(she ? the) = "+RiTa.asList
      ((rm.getCompletions(new String[]{ "she" }, new String[]{ "the" }))));
    
   // String str = rm.generateTokens(10);    
    //System.out.println("GEN(10):  "+str);     
    String[] strs = rm.generateSentences(10);    
    for (int i = 0; i < strs.length; i++)
      System.out.println(i+") "+strs[i]);*/
  }

  private String[] generateWords(int numRequested, RiMarkov model, int minLength, int maxLength)
  {
    int maxTries=1000*numRequested;
    ArrayList words = new ArrayList();
    for (int tries = 0; tries < maxTries && words.size() < numRequested; tries++)
    {
      String word = model.generateTokens(maxLength);
      String[] parts = word.split(" ");
      for (int j = 0; j < parts.length; j++)
      {
        int len = parts[j].length();
        if (len >= minLength && parts[j].matches("[a-z]*"))
          words.add(parts[j]);
      }
    }
    return (String[]) words.toArray(new String[words.size()]);
  }

}// end
